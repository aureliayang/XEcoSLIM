{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9ee5964-711f-40e6-bf38-4aa9cf0228db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "import sys \n",
    "#sys.path.append(\"./models\")\n",
    "import numpy as np \n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from tqdm import tqdm \n",
    "from data_loader import LoadPointsData2, LoadPointsDataTest2\n",
    "from utils import EarlyStopping, LRScheduler\n",
    "from network import Network2\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98416aad-0690-4ce9-ac49-99d1fab3d418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "nepochs = 50\n",
    "lr = 1e-04\n",
    "use_lr_scheduler = True\n",
    "start_epoch = 0\n",
    "\n",
    "# interval = 1\n",
    "# step_size = 1\n",
    "\n",
    "num_seeds = \"800000\"\n",
    "data_set = \"ERshrub\"\n",
    "dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8fbd059-4f1a-4ae6-a09a-acac486f2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fm and stop fm 0 10\n"
     ]
    }
   ],
   "source": [
    "start_fm = 0\n",
    "stop_fm = 10\n",
    "num_fm  = stop_fm - start_fm\n",
    "mode = 'short'\n",
    "print(\"start fm and stop fm\", start_fm, stop_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5095ca2a-7ef8-4f74-ad21-5ab7cdef7058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = \"network2\"\n",
    "num_encoder_layer = 3\n",
    "num_decoder_layer = 4\n",
    "latent_dim = 1024\n",
    "model_dir = \"\"\n",
    "# boundings = np.loadtxt(\"./test/boundings_long_1.txt\")\n",
    "# t_start = 0\n",
    "# t_end = (stop_fm - start_fm) * step_size * interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "186021a8-d504-4139-ade4-cd187d7835fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")\n",
    "checkpoint_dir = os.path.join(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f755684-48c9-4612-843b-15f01657bf82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"checkpoints\", data_set)):\n",
    "    os.mkdir(os.path.join(\"checkpoints\", data_set))\n",
    "checkpoint_dir = os.path.join(\"checkpoints\", data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea0e7416-2267-4faf-b5ac-1a82393ac2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = str(start_fm) + \"_\" + str(stop_fm) + \"_\" + data_set + \"_\" + num_seeds + \"_\" + \\\n",
    "network + \"_\" + str(latent_dim) + \"_\" + str(num_encoder_layer) + \"_\" + str(num_decoder_layer) \n",
    "if not os.path.exists(os.path.join(checkpoint_dir, prefix)):\n",
    "    os.mkdir(os.path.join(checkpoint_dir, prefix))\n",
    "checkpoint_dir = os.path.join(checkpoint_dir, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fdebca8-3e61-4402-99a3-d52d1322103a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed [8365820]\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "##! set seed 999\n",
    "manualSeed = np.random.randint(0, 9999999, 1)\n",
    "print(\"seed\", manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "##! device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64b5a7c9-779c-4453-810d-dcdd3ada320d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.load('../data_generator/data_train.pth')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \\\n",
    "                              shuffle=True, num_workers=5, drop_last=False)\n",
    "\n",
    "test_dataset = torch.load('../data_generator/data_test.pth')\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=batch_size, \\\n",
    "                              shuffle=True, num_workers=5, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42b94438-d58f-4f31-8d0e-ee3579c9e82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.9932, -0.9666,  0.0822]), tensor([-0.9932, -0.9666,  0.0832]), tensor([-0.8000]))\n",
      "800000\n",
      "800000\n",
      "4000\n",
      "(tensor([-0.9293, -0.7377,  0.1663]), tensor([-0.9293, -0.7377,  0.1673]), tensor([-0.8000]))\n",
      "80000\n",
      "400\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print (train_dataloader.dataset[5000])\n",
    "print (len(train_dataset))\n",
    "print (len(train_dataloader.dataset))\n",
    "print (len(train_dataloader))\n",
    "\n",
    "print (test_dataloader.dataset[5000])\n",
    "print (len(test_dataset))\n",
    "print (len(test_dataloader))\n",
    "       \n",
    "print (torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd0a6836-d7c2-4c77-9b87-2f72f528ab75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 192\n",
      "1 192 384\n",
      "2 384 768\n",
      "0 1 64\n",
      "1 64 128\n",
      "2 128 256\n",
      "0 1024 1024\n",
      "1 1024 512\n",
      "2 512 256\n",
      "3 256 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Network2(\n",
       "    (pos_encoder): ModuleList(\n",
       "      (0): To_Latent()\n",
       "      (1): Sine()\n",
       "      (2): To_Latent()\n",
       "      (3): Sine()\n",
       "      (4): To_Latent()\n",
       "    )\n",
       "    (activation): Sine()\n",
       "    (fc_encoder): ModuleList(\n",
       "      (0): To_Latent()\n",
       "      (1): Sine()\n",
       "      (2): To_Latent()\n",
       "      (3): Sine()\n",
       "      (4): To_Latent()\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0): To_Latent()\n",
       "      (1): Sine()\n",
       "      (2): To_Latent()\n",
       "      (3): Sine()\n",
       "      (4): To_Latent()\n",
       "      (5): Sine()\n",
       "      (6): To_Latent()\n",
       "      (7): Sine()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network2(dim, num_encoder_layer, num_decoder_layer, latent_dim)\n",
    "\n",
    "if model_dir != \"\":\n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5eb559dc-f398-4ea1-a1c9-b64bc4b4762b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Initializing learning rate scheduler\n"
     ]
    }
   ],
   "source": [
    "L1_loss = nn.L1Loss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-06)\n",
    "\n",
    "if use_lr_scheduler:\n",
    "    print('INFO: Initializing learning rate scheduler')\n",
    "    lr_scheduler = LRScheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "890fbc3c-fd59-4f82-9619-885bdc9a5f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_time = torch.cuda.Event(enable_timing=True)\n",
    "# end_time   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "train_loss = []\n",
    "test_loss  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74317a-4759-4f64-82c2-f4c77f5f906f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [01:39, 40.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0 0.14408544400520623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:07, 50.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  0 0.12385519785806537\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:39, 40.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1 0.11539401787705719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:07, 51.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  1 0.10537687130272388\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:39, 40.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2 0.09612919354811311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:08, 49.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  2 0.08804665705189109\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:41, 39.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 3 0.07869643928483129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:07, 50.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  3 0.07102221937850117\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:39, 40.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 4 0.0639296604199335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:08, 49.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4 0.05788169187493622\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:41, 39.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 5 0.05224317376315594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:07, 50.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  5 0.04802017856389284\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:38, 40.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 6 0.043022515134885905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:07, 50.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  6 0.039661643858999014\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4000it [01:39, 40.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 7 0.03631586469430476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "400it [00:07, 51.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  7 0.033422498693689705\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# start_time.record()\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + nepochs):\n",
    "\n",
    "    avg_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "\n",
    "    for i, data in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "        start = data[0].to(device)\n",
    "        end = data[1].to(device)\n",
    "        t = data[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(start, t)\n",
    "        loss = L1_loss(pred, end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss = avg_train_loss + loss.item()\n",
    "\n",
    "    train_loss.append(avg_train_loss / len(train_dataloader))\n",
    "    print(\"Average Train Loss:\", epoch, avg_train_loss / len(train_dataloader))\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "\n",
    "        avg_test_loss = 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for j, test_data in tqdm(enumerate(test_dataloader)):\n",
    "\n",
    "            start_test = test_data[0].to(device)\n",
    "            end_test = test_data[1].to(device)\n",
    "            t_test = test_data[2].to(device)\n",
    "\n",
    "            pred = model(start_test, t_test)\n",
    "            loss = L1_loss(pred, end_test)\n",
    "\n",
    "            avg_test_loss = avg_test_loss + loss.item()\n",
    "\n",
    "    if use_lr_scheduler == True:\n",
    "        lr_scheduler(avg_test_loss / len(test_dataloader))\n",
    "\n",
    "    test_loss.append(avg_test_loss / len(test_dataloader))\n",
    "    print(\"Average Test Loss: \", epoch, avg_test_loss / len(test_dataloader))\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "\n",
    "        # save model \n",
    "        path = os.path.join(checkpoint_dir, \"model_\" + str(epoch+1) + \".pth\")\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(model.module.state_dict(), path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), path)\n",
    " \n",
    "# end_time.record()\n",
    "\n",
    "# torch.cuda.synchronize()\n",
    "train_path = os.path.join(checkpoint_dir, \"train_loss.npy\")\n",
    "np.save(train_path, train_loss)\n",
    "test_path  = os.path.join(checkpoint_dir, \"test_loss.npy\")\n",
    "np.save(test_path, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604da30-a258-41c1-aa5c-0ef2efb4fa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
