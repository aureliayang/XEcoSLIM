{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ee5964-711f-40e6-bf38-4aa9cf0228db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "import sys \n",
    "#sys.path.append(\"./models\")\n",
    "import numpy as np \n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from tqdm import tqdm \n",
    "from data_loader import LoadPointsData2, LoadPointsDataTest2\n",
    "from utils import EarlyStopping, LRScheduler\n",
    "from network import Network2\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98416aad-0690-4ce9-ac49-99d1fab3d418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "nepochs = 100\n",
    "lr = 1e-04\n",
    "use_lr_scheduler = True\n",
    "start_epoch = 0\n",
    "\n",
    "# interval = 1\n",
    "# step_size = 1\n",
    "\n",
    "num_seeds = \"80000\"\n",
    "data_set = \"ERshrub\"\n",
    "dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fbd059-4f1a-4ae6-a09a-acac486f2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fm and stop fm 0 10\n"
     ]
    }
   ],
   "source": [
    "start_fm = 0\n",
    "stop_fm = 10\n",
    "num_fm  = stop_fm - start_fm\n",
    "mode = 'short'\n",
    "print(\"start fm and stop fm\", start_fm, stop_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5095ca2a-7ef8-4f74-ad21-5ab7cdef7058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = \"network2\"\n",
    "num_encoder_layer = 3\n",
    "num_decoder_layer = 4\n",
    "latent_dim = 1024\n",
    "model_dir = \"\"\n",
    "# boundings = np.loadtxt(\"./test/boundings_long_1.txt\")\n",
    "# t_start = 0\n",
    "# t_end = (stop_fm - start_fm) * step_size * interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186021a8-d504-4139-ade4-cd187d7835fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")\n",
    "checkpoint_dir = os.path.join(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f755684-48c9-4612-843b-15f01657bf82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"checkpoints\", data_set)):\n",
    "    os.mkdir(os.path.join(\"checkpoints\", data_set))\n",
    "checkpoint_dir = os.path.join(\"checkpoints\", data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0e7416-2267-4faf-b5ac-1a82393ac2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = str(start_fm) + \"_\" + str(stop_fm) + \"_\" + data_set + \"_\" + num_seeds + \"_\" + \\\n",
    "network + \"_\" + str(latent_dim) + \"_\" + str(num_encoder_layer) + \"_\" + str(num_decoder_layer) \n",
    "if not os.path.exists(os.path.join(checkpoint_dir, prefix)):\n",
    "    os.mkdir(os.path.join(checkpoint_dir, prefix))\n",
    "checkpoint_dir = os.path.join(checkpoint_dir, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdebca8-3e61-4402-99a3-d52d1322103a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed [9250659]\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "##! set seed 999\n",
    "manualSeed = np.random.randint(0, 9999999, 1)\n",
    "print(\"seed\", manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "##! device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b5a7c9-779c-4453-810d-dcdd3ada320d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data_npy = np.load(\"../double_gyre/double_gyre_sobol_5000.npy\")[:, :, 0:2]\n",
    "# train_dataset = LoadPointsDataTest2(train_data_npy, interval, num_fm, dim, boundings, t_start, t_end, step_size)\n",
    "train_dataset = torch.load('../data_generator/data.pth')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=5, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b94438-d58f-4f31-8d0e-ee3579c9e82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.9983, -0.8184,  0.0845]), tensor([-0.9983, -0.8184,  0.0855]), tensor([-0.8000]))\n",
      "80000\n",
      "800\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print (train_dataloader.dataset[5000])\n",
    "print (len(train_dataset))\n",
    "print (len(train_dataloader))\n",
    "print (torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0a6836-d7c2-4c77-9b87-2f72f528ab75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 192\n",
      "1 192 384\n",
      "2 384 768\n",
      "0 1 64\n",
      "1 64 128\n",
      "2 128 256\n",
      "0 1024 1024\n",
      "1 1024 512\n",
      "2 512 256\n",
      "3 256 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Network2(\n",
       "    (pos_encoder): ModuleList(\n",
       "      (0): To_Latent()\n",
       "      (1): Sine()\n",
       "      (2): To_Latent()\n",
       "      (3): Sine()\n",
       "      (4): To_Latent()\n",
       "    )\n",
       "    (activation): Sine()\n",
       "    (fc_encoder): ModuleList(\n",
       "      (0): To_Latent()\n",
       "      (1): Sine()\n",
       "      (2): To_Latent()\n",
       "      (3): Sine()\n",
       "      (4): To_Latent()\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0): To_Latent()\n",
       "      (1): Sine()\n",
       "      (2): To_Latent()\n",
       "      (3): Sine()\n",
       "      (4): To_Latent()\n",
       "      (5): Sine()\n",
       "      (6): To_Latent()\n",
       "      (7): Sine()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network2(dim, num_encoder_layer, num_decoder_layer, latent_dim)\n",
    "# print(model)\n",
    "if model_dir != \"\":\n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb559dc-f398-4ea1-a1c9-b64bc4b4762b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Initializing learning rate scheduler\n"
     ]
    }
   ],
   "source": [
    "L1_loss = nn.L1Loss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-06)\n",
    "\n",
    "if use_lr_scheduler:\n",
    "    print('INFO: Initializing learning rate scheduler')\n",
    "    lr_scheduler = LRScheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "890fbc3c-fd59-4f82-9619-885bdc9a5f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start_time = torch.cuda.Event(enable_timing=True)\n",
    "# end_time = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "train_loss = []\n",
    "# test_loss =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d74317a-4759-4f64-82c2-f4c77f5f906f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:23, 33.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0 0.6179694760590791\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:22, 36.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1 0.5561837133020162\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 37.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2 0.5365055638924241\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 3 0.5178909084945917\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 4 0.5005483461543918\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 5 0.489758579544723\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:22, 35.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 6 0.480843546167016\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 7 0.47689838133752344\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 8 0.47312677089124916\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 36.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 9 0.4710982459038496\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 10 0.4673957535251975\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 36.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 11 0.4661526435613632\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 12 0.46369735457003114\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 37.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 13 0.45967311922460796\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 37.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 14 0.45784636329859496\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 15 0.45595654774457217\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 37.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 16 0.45393576327711344\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:20, 38.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 17 0.45347812928259373\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "800it [00:21, 37.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 18 0.4516276263818145\n",
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "471it [00:13, 35.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m t \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(start, t)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m L1_loss(pred, end)\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:170\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:175\u001b[0m, in \u001b[0;36mDataParallel.replicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplicate\u001b[39m(\u001b[38;5;28mself\u001b[39m, module, device_ids):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m replicate(module, device_ids, \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled())\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/replicate.py:91\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     89\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(network\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     90\u001b[0m param_indices \u001b[38;5;241m=\u001b[39m {param: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(params)}\n\u001b[0;32m---> 91\u001b[0m param_copies \u001b[38;5;241m=\u001b[39m _broadcast_coalesced_reshape(params, devices, detach)\n\u001b[1;32m     93\u001b[0m buffers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(network\u001b[38;5;241m.\u001b[39mbuffers())\n\u001b[1;32m     94\u001b[0m buffers_rg \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/parallel/replicate.py:71\u001b[0m, in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Use the autograd function to broadcast if not detach\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m         tensor_copies \u001b[38;5;241m=\u001b[39m Broadcast\u001b[38;5;241m.\u001b[39mapply(devices, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [tensor_copies[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(tensors)]\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tensor_copies), \u001b[38;5;28mlen\u001b[39m(tensors))]\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start_time.record()\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + nepochs):\n",
    "    \n",
    "    avg_train_loss = 0\n",
    "    # train_bar = tqdm(enumerate(train_dataloader))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "        \n",
    "    for i, data in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "        start = data[0].to(device)\n",
    "        end = data[1].to(device)\n",
    "        t = data[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(start, t)\n",
    "        loss = L1_loss(pred, end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss = avg_train_loss + loss.item()\n",
    "\n",
    "    train_loss.append(avg_train_loss / len(train_dataloader))\n",
    "    print(\"Average Train Loss:\", epoch, avg_train_loss / len(train_dataloader))\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        \n",
    "        # save model \n",
    "        path = os.path.join(checkpoint_dir, \"model_\" + str(epoch+1) + \".pth\")\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(model.module.state_dict(), path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), path)\n",
    " \n",
    "# end_time.record()\n",
    "\n",
    "# torch.cuda.synchronize()\n",
    "train_path = os.path.join(checkpoint_dir, \"train_loss.npy\")\n",
    "np.save(train_path, train_loss)\n",
    "# test_path = os.path.join(checkpoint_dir, \"test_loss.npy\")\n",
    "# np.save(test_path, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604da30-a258-41c1-aa5c-0ef2efb4fa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
